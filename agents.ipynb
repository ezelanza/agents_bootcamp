{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre : Instalacion de requerimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/emlanza/Library/CloudStorage/OneDrive-IntelCorporation/Documents/GitHub repos/agents_bootcamp/agents/bin/pip: line 2: /Users/emlanza/Library/CloudStorage/OneDrive-IntelCorporation/Documents/GitHub repos/agents/bin/python: No such file or directory\n",
      "/Users/emlanza/Library/CloudStorage/OneDrive-IntelCorporation/Documents/GitHub repos/agents_bootcamp/agents/bin/pip: line 2: exec: /Users/emlanza/Library/CloudStorage/OneDrive-IntelCorporation/Documents/GitHub repos/agents/bin/python: cannot execute: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduccion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Que es un Agente?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los agentes son sistemas aut√≥nomos que perciben su entorno, razonan y ejecutan acciones para alcanzar objetivos espec√≠ficos. Pueden interactuar con usuarios, recuperar y procesar datos, y ejecutar tareas basadas en reglas o modelos de aprendizaje.\n",
    "\n",
    "Caracter√≠sticas Clave:\n",
    "- ‚úÖ Aut√≥nomos ‚Äì Operan con m√≠nima intervenci√≥n humana\n",
    "- ‚úÖ Perceptivos ‚Äì Analizan informaci√≥n de texto, voz, im√°genes o datos estructurados\n",
    "- ‚úÖ Orientados a objetivos ‚Äì Trabajan para cumplir tareas como responder preguntas o resumir contenido\n",
    "- ‚úÖ Interactivos ‚Äì Se comunican con humanos o con otros agentes\n",
    "- ‚úÖ Adaptativos ‚Äì Mejoran con el tiempo mediante aprendizaje o retroalimentaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tipos de Agentes**  \n",
    "Los agentes se pueden clasificar seg√∫n su capacidad de razonamiento y toma de decisiones:\n",
    "\n",
    "| Tipo | Descripci√≥n | Ejemplo |\n",
    "|------|------------|---------|\n",
    "| **Agentes Reactivos** | Responden solo a entradas actuales, sin memoria | Chatbot que responde preguntas directas |\n",
    "| **Agentes Basados en Objetivos** | Usan objetivos para guiar sus decisiones | Sistemas de recomendaci√≥n |\n",
    "| **Agentes Basados en Utilidad** | Optimizan la mejor decisi√≥n posible | Coches aut√≥nomos ajustando velocidad |\n",
    "| **Agentes de Aprendizaje** | Mejoran con datos y experiencia | Modelos de IA ajustados para tareas espec√≠ficas |\n",
    "\n",
    "### **Ejemplo: Diferencia entre Agentes Reactivos y Basados en Objetivos**  \n",
    "üöó **Agente Reactivo:** Un coche aut√≥nomo frena cuando el sem√°foro est√° en rojo, pero no planea m√°s all√°.  \n",
    "üõ£Ô∏è **Agente Basado en Objetivos:** El coche no solo frena, sino que tambi√©n ajusta su velocidad para optimizar el consumo de combustible.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Partes Importantes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "LLM son modelos estaticos-Amplio y estatico conocimiento.\n",
    "RAG tuvo gran popularidad proveyendo context, enfocando la respuesta del LLM sobre el topico deseado y proveyendo context externo (LLM interpreta la info del prompt)\n",
    "Necesidad\n",
    "- Conectar con el mundo externo \n",
    "- Activar automatizaciones (Ejecutar tareas)\n",
    "- Especialista en tareas especificas \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. üöÄ Construyendo un Agente de IA desde Cero (Conceptual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "En este ejercicio, implementaremos un **agente de IA sin usar un framework como Lnagchain**. En su lugar, programaremos manualmente la l√≥gica para decidir si el agente debe usar **GPT-4** o una **herramienta de c√°lculo**.\n",
    "\n",
    "---\n",
    "\n",
    "### üìå ¬øC√≥mo Funciona un Agente de IA?\n",
    "\n",
    "Un agente de IA sigue estos pasos:\n",
    "\n",
    "1Ô∏è‚É£ **Analiza la entrada del usuario** ‚Üí Decide si necesita una herramienta o si puede responder directamente.  \n",
    "2Ô∏è‚É£ **Elige una acci√≥n** ‚Üí Llama a una herramienta (ej. una calculadora) o usa el modelo de lenguaje (GPT-4).  \n",
    "3Ô∏è‚É£ **Ejecuta la acci√≥n** ‚Üí Si usa una herramienta, procesa la entrada antes de responder.  \n",
    "4Ô∏è‚É£ **Devuelve la respuesta** ‚Üí Muestra el resultado al usuario.  \n",
    "\n",
    "En este caso, crearemos un agente que **puede hacer c√°lculos y responder preguntas generales con GPT-4**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## üöÄ Paso 1: Configurar una agente que elija entre GPT-4 y la Calculadora\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos dos funciones:\n",
    "- Una para llamar a **GPT-4**.\n",
    "- Otra para ejecutar una **calculadora**.\n",
    "\n",
    "‚úÖ ¬øQu√© hace este c√≥digo?\n",
    "\n",
    "llamar_gpt(): Llama a GPT-4 para generar respuestas.\n",
    "calculadora(): Eval√∫a expresiones matem√°ticas simples (12 * 8, 5 + 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source ./open_ai.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Usando GPT-4\n",
      "La capital de Francia es Par√≠s.\n",
      "üîπ Usando Calculadora\n",
      "96\n",
      "üîπ Usando GPT-4\n",
      "Claro, aqu√≠ tienes uno:\n",
      "\n",
      "¬øQu√© hace una abeja en el gimnasio?\n",
      "\n",
      "Zum-ba.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# Coloca tu clave de API aqu√≠\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Funci√≥n que simula la acci√≥n de una calculadora b√°sica para operaciones matem√°ticas\n",
    "def calculadora(entrada):\n",
    "    try:\n",
    "        # Evaluamos la operaci√≥n matem√°tica\n",
    "        resultado = eval(entrada)\n",
    "        return resultado\n",
    "    except:\n",
    "        return \"Error en la operaci√≥n\"\n",
    "\n",
    "# Funci√≥n que simula la llamada a GPT-4\n",
    "def llamar_gpt(entrada):\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": entrada}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error al llamar a GPT: {str(e)}\"\n",
    "\n",
    "# Funci√≥n principal que act√∫a como el agente\n",
    "def agente(input_texto):\n",
    "    # 1Ô∏è‚É£ Analiza la entrada\n",
    "    if re.match(r'^[\\d+\\-*/(). ]+$', input_texto):  # Verifica si es una operaci√≥n matem√°tica\n",
    "        print(\"üîπ Usando Calculadora\")\n",
    "        return calculadora(input_texto)\n",
    "    \n",
    "    # 2Ô∏è‚É£ Elige la acci√≥n\n",
    "    print(\"üîπ Usando GPT-4\")\n",
    "    return llamar_gpt(input_texto)\n",
    "\n",
    "# Casos de prueba\n",
    "print(agente(\"¬øCu√°l es la capital de Francia?\"))  # Usa GPT-4\n",
    "print(agente(\"12 * 8\"))                           # Usa la calculadora\n",
    "print(agente(\"Cu√©ntame un chiste\"))               # Usa GPT-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien este caso ejemplifica la logica, la realidad es que la implementacion utiliza el poder de razonamiento que tiene el LLM para elegir si se hace necesario usar la herramienta o no. En el caso anterior, cuando entrada que no matchee con la expresion definida, como puede ser : \"Me puedes calcular el valor de 12 * 8\" sera resuelta por el LLM.\n",
    "\n",
    "Como se puede utilizar entonces una agente?\n",
    "\n",
    "**La respuesta esta en la utilizacion del poder de razonamiento del LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "#OPENAI_API_KEY=\"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\"\n",
    "# Ensure the API key is set in the environment\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "llm = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "\n",
    "# Un agente tiene siempre una herramienta (Tool) la cual realiza las acciones que el LLM no es capaz de responder. En este caso se utiliza una calculadora como ejemplo, \n",
    "\n",
    "def calculadora(input):\n",
    "    try:\n",
    "        return str(eval(input))\n",
    "    except:\n",
    "        return \"Error en la operaci√≥n\"\n",
    "\n",
    "def llamar_gpt(prompt):\n",
    "    response = llm.chat.completions.create(  # Use chat.completions.create\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Eres un asistente inteligente\"},  # Optional system message\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def agente(input_texto):\n",
    "    prompt = f\"¬øLa siguiente entrada es una operaci√≥n matem√°tica o una pregunta com√∫n? Entrada: '{input_texto}'\"\n",
    "    respuesta = llamar_gpt(prompt)\n",
    "    \n",
    "    print(\"LLM respuesta:\",respuesta)\n",
    "\n",
    "    if \"matem√°tica\" in respuesta.lower():\n",
    "        print(\"üîπ Usando la Calculadora\")\n",
    "        return calculadora(input_texto)\n",
    "    \n",
    "    print(\"üîπ Usando GPT-4\")\n",
    "    return llamar_gpt(input_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM respuesta: La siguiente entrada es una pregunta com√∫n.\n",
      "üîπ Usando GPT-4\n",
      "La capital de Francia es Par√≠s.\n",
      "LLM respuesta: La entrada es una operaci√≥n matem√°tica.\n",
      "üîπ Usando la Calculadora\n",
      "96\n",
      "LLM respuesta: La siguiente entrada es una pregunta com√∫n.\n",
      "üîπ Usando GPT-4\n",
      "Claro, ah√≠ va: \n",
      "\n",
      "¬øPor qu√© los p√°jaros no usan Facebook?\n",
      "\n",
      "Porque ya tienen Twitter.\n"
     ]
    }
   ],
   "source": [
    "# Casos de prueba\n",
    "print(agente(\"¬øCu√°l es la capital de Francia?\"))  # Deber√≠a usar GPT-4\n",
    "print(agente(\"12 * 8\"))                           # Deber√≠a usar la calculadora\n",
    "print(agente(\"Cu√©ntame un chiste\"))               # Deber√≠a usar GPT-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Paso 2: Implementar la L√≥gica del Agente con un framework como Langchain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora escribimos la funci√≥n `agente()`, que decide cu√°ndo usar GPT-4 y cu√°ndo usar la calculadora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to provide the answer to the question.\n",
      "Action: \n",
      "Final Answer: Par√≠s.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Par√≠s.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the calculator to multiply 12 by 8.\n",
      "Action: Calculadora\n",
      "Action Input: 12*8\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m96\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 96\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.tools import Tool\n",
    "import os\n",
    "\n",
    "# Creacion de un una funcion para c√°lculos matem√°ticos\n",
    "def calcular(entrada):\n",
    "    \"\"\"Eval√∫a expresiones matem√°ticas simples\"\"\"\n",
    "    try:\n",
    "        return str(eval(entrada))\n",
    "    except Exception as e:\n",
    "        return f\"Error en el c√°lculo: {e}\"\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "#Utiliza el metodo Tool\n",
    "Math_tool = Tool(\n",
    "    name=\"Calculadora\",\n",
    "    func=calcular,\n",
    "    description=\"√ötil SOLAMENTE para calcular expresiones matem√°ticas simples. Entrada esperada: '2+2'\"\n",
    ")   #Puede probar quitanto SOLAMENTE y vera la diferencia. El modelo solo tiene una tool y la intentara usar.Cuando el agente tiene herramientas limitadas, puede intentar usar lo que tiene, incluso si no es apropiado.\n",
    "\n",
    "\n",
    "# Inicializar el agente con herramientas adicionales\n",
    "agent = initialize_agent(\n",
    "    tools=[Math_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Probar el agente\n",
    "print(agent.run(\"¬øCu√°l es la capital de Francia?\"))\n",
    "print(agent.run(\"¬øCu√°nto es 12 * 8?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Paso 3 : Implementar una Tool que conecte al exterior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora escribimos la funci√≥n `agente()`, que decide cu√°ndo usar GPT y cuando realizar una busqueda en internet. \n",
    "\n",
    "Langchain provee una serie de APIs (Tools), en este caso usaremos `DuckDuckGoSearchResults`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kw/1h25ypjx3qlgy0kwpr9s61qm0000gn/T/ipykernel_1170/1673762824.py:9: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(temperature=0)\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Inicializa el modelo OpenAI\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# Crea la herramienta de b√∫squeda (consulta URLs a trav√©s de DuckDuckGo)\n",
    "search = DuckDuckGoSearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Pregunta: ¬øQui√©n es el presidente de Estados Unidos HOY?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Necesito buscar en internet para encontrar la respuesta m√°s actualizada.\n",
      "Action: Search\n",
      "Action Input: 'presidente de Estados Unidos hoy'\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3msnippet: El presidente de Estados Unidos, Donald Trump, durante el desfile de la 60¬™ inauguraci√≥n presidencial en el Capital One Arena en Washington, DC, el lunes 20 de enero de 2025. ... \"Hoy tomar√°n el juramento de su oficina y seremos testigos de una transferencia pac√≠fica del poder en el coraz√≥n de nuestra democracia\". ..., title: Donald Trump ya es presidente de EE.UU.: anuncios y minuto a minuto, link: https://www.bloomberglinea.com/mundo/estados-unidos/en-vivo-posesion-de-donald-trump-hoy-como-presidente-de-eeuu-programacion-y-discurso/, snippet: Donald Trump firm√≥ el lunes una serie de decretos, entre ellas revocar 78 medidas de Joe Biden, horas despu√©s de convertirse oficialmente en el 47¬∫ presidente de Estados Unidos. Otros decretos ..., title: Resumen de noticias de la toma de posesi√≥n de Trump como presidente de ..., link: https://cnnespanol.cnn.com/2025/01/20/toma-posesion-trump-presidente-eeuu-trax/, snippet: Donald Trump asumir√° este lunes como el 47¬∫ presidente de Estados Unidos, marcando un regreso hist√≥rico al poder tras su primer mandato entre 2017 y 2021 - Heraldo USA. 1 mar 2025. Estados Unidos. Actualidad. Migraci√≥n. ... En VIVO: Toma de posesi√≥n de Donald Trump como el presidente n√∫mero 47 de EEUU hoy 20 de enero 2025, title: En VIVO: Toma de posesi√≥n de Donald Trump como el presidente n√∫mero 47 ..., link: https://www.heraldousa.com/estados-unidos/2025/01/20/en-vivo-toma-de-posesion-de-donald-trump-como-el-presidente-numero-47-de-eeuu-hoy-20-de-enero-2025/, snippet: Trump tambi√©n se jact√≥ de haber ganado el voto popular: ser√≠a la primera vez en dos d√©cadas que un candidato republicano lo logra. Con esta victoria, se convierte en el primer presidente en ..., title: Donald Trump es reelegido como presidente de Estados Unidos 2024 tras ..., link: https://larepublica.pe/mundo/2024/11/05/elecciones-estados-unidos-2024-en-vivo-como-van-las-votaciones-segun-colegio-electoral-y-conteo-rapido-de-votos-elecciones-en-estados-unidos-quien-ganara-en-estados-unidos-quien-va-ganando-las-elecciones-2024-hoy-88016\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Hay muchos resultados diferentes, pero parece que Donald Trump es el presidente de Estados Unidos hoy.\n",
      "Final Answer: Donald Trump\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Respuesta: Donald Trump\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Inicializa el modelo OpenAI\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# Herramienta de b√∫squeda\n",
    "search = DuckDuckGoSearchResults()\n",
    "\n",
    "# Prompt simple para an√°lisis\n",
    "analisis_prompt = PromptTemplate(\n",
    "    input_variables=[\"pregunta\"],\n",
    "    template=\"\"\"¬øEsta pregunta requiere informaci√≥n actualizada de internet para ser respondida correctamente?\n",
    "Pregunta: {pregunta}\n",
    "\n",
    "Responde solo 'search' o 'respond':\"\"\"\n",
    ")\n",
    "\n",
    "# Crear la cadena de an√°lisis\n",
    "analisis_chain = LLMChain(llm=llm, prompt=analisis_prompt)\n",
    "\n",
    "# Define las herramientas disponibles\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search.run,\n",
    "        description=\"Busca informaci√≥n en internet cuando necesites datos actualizados.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Inicializa el agente\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "def responder_pregunta(query):\n",
    "    \"\"\"\n",
    "    Funci√≥n que decide si buscar en internet o responder directamente\n",
    "    \"\"\"\n",
    "    decision = analisis_chain.run(query).strip().lower()\n",
    "    \n",
    "    if decision == \"search\":\n",
    "        return agent.run(query)\n",
    "    else:\n",
    "        return llm.predict(query)\n",
    "\n",
    "# Ejemplo de uso (Probar con diferentes preguntas)\n",
    "pregunta = \"¬øQui√©n es el presidente de Estados Unidos HOY?\"\n",
    "#pregunta = \"Resultado del mas reciente partido de River Plate ?\"\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"Pregunta: {pregunta}\")\n",
    "respuesta = responder_pregunta(pregunta)\n",
    "print(f\"Respuesta: {respuesta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Paso 4 : Multiples Agentes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se cuenta con mas de 1 agente, se empieza a poner mas interesante. Si se van a tener varios agentes para realizar diferentes tareas, se va a necesitar entonces un `Supervisor`. \n",
    "En este ejemplo, un agente supervisor gestionar√° varios agentes especializados, cada uno responsable de una tarea espec√≠fica, como buscar informaci√≥n en la web, generar texto o realizar c√°lculos. El agente supervisor ser√° el encargado de decidir qu√© agente utilizar seg√∫n la consulta que reciba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El agente supervisor ha escogido el agente: B√∫squeda Web\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the B√∫squeda Web tool to search for information.\n",
      "Action: B√∫squeda Web\n",
      "Action Input: 'Albert Einstein'\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3msnippet: Albert Einstein (born March 14, 1879, Ulm, W√ºrttemberg, Germany‚Äîdied April 18, 1955, Princeton, New Jersey, U.S.) was a German-born physicist who developed the special and general theories of relativity and won the Nobel Prize for Physics in 1921 for his explanation of the photoelectric effect.Einstein is generally considered the most influential physicist of the 20th century., title: Albert Einstein | Biography, Education, Discoveries, & Facts - Britannica, link: https://www.britannica.com/biography/Albert-Einstein, snippet: Albert Einstein's birthday and education. Einstein was born in Ulm, in the German state of W√ºrttemberg, on March 14, 1879, according to a biography from the Nobel Prize organization. His family ..., title: Albert Einstein: Biography, facts and impact on science, link: https://www.livescience.com/albert-einstein.html, snippet: Albert Einstein was born on March 14, 1879 in the German city of Ulm beside the Danube River. His parents were secular Jews who were part of the middle class. Just one year after the birth of little Albert, the family moved to Munich, where Einstein's father Hermann set up an electrical engineering business with his brother Jakob., title: Albert Einstein: The Greatest Scientist of the 20th Century - TheCollector, link: https://www.thecollector.com/albert-einstein-greatest-scientist-20th-century/, snippet: Albert Einstein was a prominent German mathematician and physicist, best known for formulating the theories of special and general relativity, which revolutionized our understanding of space, time, and gravity. Born on March 14, 1879, in Ulm, W√ºrttemberg, Germany, he displayed an early passion for inquiry and a deep intellect, despite facing ..., title: Albert Einstein \"Physicist\" - Biography, Age, Married and Children, link: https://biographyhost.com/p/albert-einstein-biography.html\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should specify that I want the information in Spanish.\n",
      "Action: B√∫squeda Web\n",
      "Action Input: 'Albert Einstein en espa√±ol'\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3msnippet: Albert Einstein, el genio del siglo XX Aunque se considera como el ¬´padre de la bomba at√≥mica¬ª, siempre advirti√≥ sobre el peligro de su uso, abog√≥ por el pacifismo, el federalismo mundial, el internacionalismo, el sionismo y el socialismo democr√°tico, con una fuerte devoci√≥n por la libertad individual y la libertad de expresi√≥n., title: Albert Einstein, el genio del siglo XX | Instituto Nacional de ..., link: https://www.gob.mx/inin/es/articulos/albert-einstein-el-genio-del-siglo-xx?idiom=es, snippet: Albert Einstein naci√≥ el 14 de marzo de 1879 en Ulm, una ciudad en el Reino de Wurtemberg, que entonces formaba parte del Imperio Alem√°n. Ven√≠a de una familia jud√≠a de clase media, algo que marcar√≠a su vida d√©cadas despu√©s, con el ascenso del nazismo. Hay que decir que, a pesar de que su educaci√≥n temprana incluy√≥ ense√±anzas sobre el ..., title: Albert Einstein, el genio exc√©ntrico que cambi√≥ nuestra visi√≥n del universo, link: https://historia.nationalgeographic.com.es/a/albert-einstein-genio-excentrico-que-cambio-nuestra-vision-universo_23092, snippet: Prueba gratuita de 30 d√≠as: https://labibliotecafantasma.es/go/prueba_gratuitaüéß Audiolibro: Albert Einstein (Edici√≥n en espa√±ol) Escritor: Online Studio..., title: Albert Einstein (Edici√≥n en espa√±ol) (Audiolibro) - YouTube, link: https://www.youtube.com/watch?v=J810RXPcJ9c, snippet: Albert Einstein (1879-1955) fue un destacado f√≠sico te√≥rico de origen jud√≠o nacido en Alemania, reconocido como uno de los cient√≠ficos m√°s influyentes y relevantes del siglo XX. Su contribuci√≥n m√°s famosa, la teor√≠a de la relatividad, se considera uno de los pilares fundamentales para el avance de la f√≠sica moderna., title: Albert Einstein: El genio que revolucion√≥ la f√≠sica - Biograf√≠a ..., link: https://historiadeltodo.com/albert-einstein-el-genio-que-revoluciono-la-fisica-biografia-completa/\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Albert Einstein fue un f√≠sico alem√°n que desarroll√≥ las teor√≠as de la relatividad y gan√≥ el Premio Nobel de F√≠sica en 1921. Tambi√©n fue un defensor del pacifismo, el sionismo y el socialismo democr√°tico. Naci√≥ el 14 de marzo de 1879 en Ulm, Alemania y falleci√≥ el 18 de abril de 1955 en Princeton, Nueva Jersey, Estados Unidos.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Respuesta: Albert Einstein fue un f√≠sico alem√°n que desarroll√≥ las teor√≠as de la relatividad y gan√≥ el Premio Nobel de F√≠sica en 1921. Tambi√©n fue un defensor del pacifismo, el sionismo y el socialismo democr√°tico. Naci√≥ el 14 de marzo de 1879 en Ulm, Alemania y falleci√≥ el 18 de abril de 1955 en Princeton, Nueva Jersey, Estados Unidos.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Inicializa el modelo OpenAI\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# Herramienta de b√∫squeda en DuckDuckGo\n",
    "search = DuckDuckGoSearchResults()\n",
    "\n",
    "# Herramienta para generar respuestas de texto\n",
    "def responder_texto(query):\n",
    "    return f\"Respondiendo directamente a la pregunta: {query}\"\n",
    "\n",
    "# Define los agentes especializados\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"B√∫squeda Web\",\n",
    "        func=search.run,\n",
    "        description=\"Busca informaci√≥n en la web.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Generador de Texto\",\n",
    "        func=responder_texto,\n",
    "        description=\"Genera respuestas basadas en texto preexistente.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Agente Supervisor\n",
    "def agente_supervisor(query):\n",
    "    # Si la consulta tiene una pregunta de tipo \"qui√©n\" o \"qu√©\", usa la b√∫squeda\n",
    "    if \"qui√©n\" in query.lower() or \"qu√© es\" in query.lower():\n",
    "        return \"B√∫squeda Web\"\n",
    "    else:\n",
    "        return \"Generador de Texto\"\n",
    "\n",
    "# Inicializa los agentes especializados\n",
    "agente_supervisado = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Funci√≥n para gestionar la consulta\n",
    "def gestionar_consulta(query):\n",
    "    agente_escogido = agente_supervisor(query)\n",
    "    print(f\"El agente supervisor ha escogido el agente: {agente_escogido}\")\n",
    "    \n",
    "    # Ejecuta el agente seleccionado\n",
    "    if agente_escogido == \"B√∫squeda Web\":\n",
    "        response = agente_supervisado.run(f\"Busca informaci√≥n sobre: {query}\")\n",
    "    else:\n",
    "        response = agente_supervisado.run(query)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Ejemplo de consulta\n",
    "query = \"¬øQui√©n es Albert Einstein? En espa√±ol\"\n",
    "respuesta = gestionar_consulta(query)\n",
    "print(f\"Respuesta: {respuesta}\")\n",
    "\n",
    "# Otro ejemplo, donde el agente responder√° directamente\n",
    "#query2 = \"Explica la teor√≠a de la relatividad\"\n",
    "#respuesta2 = gestionar_consulta(query2)\n",
    "#print(f\"Respuesta: {respuesta2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Paso 5 : SQL Agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asegurarse de tener instalado postgres en su maquina, Referirse al siguiente link para https://www.postgresql.org/download/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ej en MAC\n",
    "- brew install postgresql@14 \n",
    "- brew services start postgresql\n",
    "\n",
    "Una vez creado desde el terminal ejecuta `psql postgres`\n",
    "\n",
    "Esto deber√≠a iniciar una sesi√≥n de PostgreSQL usando el usuario de tu sistema (por ejemplo, si tu usuario de macOS es tu_usuario, PostgreSQL tambi√©n usar√° tu_usuario como nombre de usuario).\n",
    "\n",
    "Una vez dentro de la consola de PostgreSQL, puedes listar todos los usuarios con el siguiente comando:\n",
    "`\\du`\n",
    "\n",
    "Esto mostrar√° una lista de los roles de PostgreSQL. En una instalaci√≥n de Homebrew, deber√≠as ver un usuario con el mismo nombre que tu usuario del sistema, por ejemplo tu_usuario.\n",
    "\n",
    "`ALTER USER tu_usuario WITH PASSWORD 'nueva_contrase√±a';`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Column, Integer, String, Date, Float, ForeignKey, Numeric\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import relationship, sessionmaker\n",
    "from datetime import date, timedelta\n",
    "import random\n",
    "\n",
    "# Conexi√≥n a la base de datos PostgreSQL\n",
    "DATABASE_URI = \"postgresql://test:admin@localhost:5432/test_db\"\n",
    "engine = create_engine(DATABASE_URI, echo=True)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Base para definir las tablas\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kw/1h25ypjx3qlgy0kwpr9s61qm0000gn/T/ipykernel_61916/2578386893.py:8: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, Column, Integer, String, ForeignKey, Float, Date\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker, relationship\n",
    "from datetime import date, timedelta\n",
    "import random\n",
    "\n",
    "# Base class for ORM\n",
    "Base = declarative_base()\n",
    "\n",
    "# Define the Autor model\n",
    "class Autor(Base):\n",
    "    __tablename__ = 'autores'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    nombre = Column(String, nullable=False)\n",
    "    libros = relationship(\"Libro\", back_populates=\"autor\")  # Relationship with Libro\n",
    "\n",
    "# Define the Libro model\n",
    "class Libro(Base):\n",
    "    __tablename__ = 'libros'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    nombre = Column(String, nullable=False)\n",
    "    autor_id = Column(Integer, ForeignKey('autores.id'), nullable=False)\n",
    "    precio = Column(Float, nullable=False)\n",
    "    autor = relationship(\"Autor\", back_populates=\"libros\")  # Relationship with Autor\n",
    "    ventas = relationship(\"Venta\", back_populates=\"libro\")  # Relationship with Venta\n",
    "\n",
    "# Define the Venta model\n",
    "class Venta(Base):\n",
    "    __tablename__ = 'ventas'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    libro_id = Column(Integer, ForeignKey('libros.id'), nullable=False)\n",
    "    cantidad_vendida = Column(Integer, nullable=False)\n",
    "    fecha_venta = Column(Date, nullable=False)\n",
    "    libro = relationship(\"Libro\", back_populates=\"ventas\")  # Relationship with Libro\n",
    "\n",
    "# Create the database and tables\n",
    "engine = create_engine('sqlite:///mi_base_de_datos.db')\n",
    "Base.metadata.create_all(engine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 registros de ventas fueron insertados con √©xito.\n"
     ]
    }
   ],
   "source": [
    "# Create a session for interacting with the database\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Function to insert random values into the database\n",
    "def insertar_valores_aleatorios(cantidad=40):\n",
    "    autores = [\"Juan P√©rez\", \"Mar√≠a G√≥mez\", \"Carlos Ruiz\", \"Ana Mart√≠nez\", \"Luis Rodr√≠guez\"]\n",
    "    libros = [\"El Gran Libro\", \"Ciencia Avanzada\", \"La Historia Completa\", \"Misterio No Resuelto\", \"El Viaje √âpico\"]\n",
    "    precios_libros = [100.0, 75.0, 50.0, 120.0, 95.0]\n",
    "    \n",
    "    for _ in range(cantidad):\n",
    "        autor_nombre = random.choice(autores)\n",
    "        libro_nombre = random.choice(libros)\n",
    "        precio_libro = random.choice(precios_libros)\n",
    "        cantidad_vendida = random.randint(1, 10)\n",
    "        fecha_venta = date.today() - timedelta(days=random.randint(0, 30))  # Fecha aleatoria\n",
    "\n",
    "        # Create and insert a new Autor\n",
    "        autor = Autor(nombre=autor_nombre)\n",
    "        session.add(autor)\n",
    "        session.commit()  # Commit to get the autor.id\n",
    "\n",
    "        # Create and insert a new Libro associated with the Autor\n",
    "        libro = Libro(nombre=libro_nombre, autor_id=autor.id, precio=precio_libro)\n",
    "        session.add(libro)\n",
    "        session.commit()  # Commit to get the libro.id\n",
    "\n",
    "        # Create and insert a new Venta associated with the Libro\n",
    "        venta = Venta(libro_id=libro.id, cantidad_vendida=cantidad_vendida, fecha_venta=fecha_venta)\n",
    "        session.add(venta)\n",
    "\n",
    "    session.commit()\n",
    "    print(f\"{cantidad} registros de ventas fueron insertados con √©xito.\")\n",
    "\n",
    "# Call the function to insert 40 random records\n",
    "insertar_valores_aleatorios(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to obtain the sales of the book 'El Gran Libro'.\n",
      "Action: Obtener Ventas del Libro\n",
      "Action Input: 'El Gran Libro'\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mLibro no encontrado.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m The book 'El Gran Libro' may not exist in the database.\n",
      "Action: Obtener Autor del Libro\n",
      "Action Input: 'El Gran Libro'\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mLibro no encontrado.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I still can't find the book 'El Gran Libro'.\n",
      "Final Answer: This book may not exist in the database.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "This book may not exist in the database.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find the author of the book 'Ciencia Avanzada'.\n",
      "Action: Obtener Autor del Libro\n",
      "Action Input: 'Ciencia Avanzada'\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mLibro no encontrado.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Since the book was not found, I cannot obtain the author.\n",
      "Final Answer: No se puede determinar el autor de 'Ciencia Avanzada'.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "No se puede determinar el autor de 'Ciencia Avanzada'.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import date\n",
    "import random\n",
    "\n",
    "# Crear un motor de SQLAlchemy para conectarse a la base de datos SQLite\n",
    "engine = create_engine('sqlite:///mi_base_de_datos.db')\n",
    "\n",
    "# Crear una sesi√≥n\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Definir las herramientas para el agente (basadas en la base de datos)\n",
    "def obtener_ventas_libro(libro_nombre):\n",
    "    \"\"\"\n",
    "    Funci√≥n para obtener las ventas de un libro espec√≠fico.\n",
    "    \"\"\"\n",
    "    libro = session.query(Libro).filter(Libro.nombre == libro_nombre).first()\n",
    "    if libro:\n",
    "        ventas = session.query(Venta).filter(Venta.libro_id == libro.id).all()\n",
    "        return f\"Ventas de '{libro.nombre}': {len(ventas)} ventas.\"\n",
    "    else:\n",
    "        return \"Libro no encontrado.\"\n",
    "\n",
    "def obtener_autor_libro(libro_nombre):\n",
    "    \"\"\"\n",
    "    Funci√≥n para obtener el autor de un libro.\n",
    "    \"\"\"\n",
    "    libro = session.query(Libro).filter(Libro.nombre == libro_nombre).first()\n",
    "    if libro:\n",
    "        autor = session.query(Autor).filter(Autor.id == libro.autor_id).first()\n",
    "        return f\"El autor de '{libro.nombre}' es {autor.nombre}.\"\n",
    "    else:\n",
    "        return \"Libro no encontrado.\"\n",
    "\n",
    "# Definir las herramientas de LangChain\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Obtener Ventas del Libro\",\n",
    "        func=obtener_ventas_libro,\n",
    "        description=\"Este agente puede obtener la cantidad de ventas de un libro espec√≠fico.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Obtener Autor del Libro\",\n",
    "        func=obtener_autor_libro,\n",
    "        description=\"Este agente puede obtener el autor de un libro espec√≠fico.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Usar OpenAI como LLM\n",
    "llm = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "\n",
    "\n",
    "# Inicializar el agente de LangChain con herramientas y el LLM\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "\n",
    "# Funci√≥n para interactuar con el agente\n",
    "def interactuar_con_agente(pregunta):\n",
    "    respuesta = agent.run(pregunta)\n",
    "    return respuesta\n",
    "\n",
    "# Probar el agente con algunas preguntas\n",
    "print(interactuar_con_agente(\"¬øCu√°ntas ventas tiene el libro 'El Gran Libro'?\"))\n",
    "print(interactuar_con_agente(\"¬øQui√©n es el autor de 'Ciencia Avanzada'?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAR EL LLM PARA REALIZAR LA SQL\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# Crear un prompt para que el LLM genere una consulta SQL\n",
    "prompt_sql = \"\"\"\n",
    "Dado el siguiente esquema de base de datos:\n",
    "- Tabla 'Autores': id (integer), nombre (text)\n",
    "- Tabla 'Libros': id (integer), nombre (text), autor_id (integer), precio (float)\n",
    "- Tabla 'Ventas': id (integer), libro_id (integer), cantidad_vendida (integer), fecha_venta (date)\n",
    "\n",
    "Escribe una consulta SQL que obtenga las ventas de un libro llamado '{libro_nombre}'.\n",
    "\"\"\"\n",
    "\n",
    "# Crear la cadena de LLM que tomar√° la entrada del usuario y generar√° una consulta SQL\n",
    "sql_prompt = PromptTemplate(input_variables=[\"libro_nombre\"], template=prompt_sql)\n",
    "llm_chain = LLMChain(llm=llm, prompt=sql_prompt)\n",
    "\n",
    "# Crear la conexi√≥n con la base de datos\n",
    "engine = create_engine('sqlite:///mi_base_de_datos.db')  # Cambia a tu base de datos\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Funci√≥n para generar el SQL y ejecutar la consulta\n",
    "def generar_y_ejecutar_sql(libro_nombre):\n",
    "    # Generar el SQL con el LLM\n",
    "    sql_query = llm_chain.run(libro_nombre=libro_nombre)\n",
    "    print(f\"Generando SQL: {sql_query}\")\n",
    "    \n",
    "    # Ejecutar la consulta generada\n",
    "    result = session.execute(text(sql_query)).fetchall()\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando SQL: \n",
      "SELECT cantidad_vendida, fecha_venta \n",
      "FROM Ventas \n",
      "WHERE libro_id = (SELECT id FROM Libros WHERE nombre = 'Ventas del El Gran Libro');\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Probar la consulta generada\n",
    "resultados = generar_y_ejecutar_sql(\"Ventas del El Gran Libro\")\n",
    "print(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Paso 6 : Crea el planeador de fiestas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La aplicaci√≥n est√° estructurada en varios archivos que trabajan juntos para proporcionar la funcionalidad completa:\n",
    "\n",
    "**Archivos Principales**\n",
    "\n",
    "`planificador_fiestas_app.py`\n",
    "- Prop√≥sito: Interfaz gr√°fica de usuario con Streamlit\n",
    "- Contenido:\n",
    "    - Dise√±o de la interfaz de usuario\n",
    "    - Formularios para entrada de datos\n",
    "    - Visualizaci√≥n de resultados\n",
    "    - Manejo de la interacci√≥n del usuario\n",
    "    - Estilos CSS personalizados\n",
    "\n",
    "`plan_mi_fiesta.py`\n",
    "- Prop√≥sito: Implementaci√≥n de agentes y l√≥gica de coordinaci√≥n\n",
    "- Contenido:\n",
    "    - Clase MockLLM que simula respuestas de IA\n",
    "    - Funciones chef_chain, dj_chain y decorator_chain\n",
    "    - Clase PartyCoordinator que orquesta la comunicaci√≥n entre agentes\n",
    "    - L√≥gica de interacci√≥n y colaboraci√≥n entre agentes\n",
    "\n",
    "`gestor_base_de_datos.py`\n",
    "- Prop√≥sito: Gesti√≥n de base de datos y persistencia\n",
    "- Contenido:\n",
    "    - Modelo de datos con SQLAlchemy\n",
    "    - Clase PartyPlan para estructura de datos\n",
    "    - Clase DatabaseManager con m√©todos CRUD\n",
    "    - Consultas para estad√≠sticas y b√∫squeda\n",
    "\n",
    "`party_planner.db`\n",
    "\n",
    "- Prop√≥sito: Almacenamiento de datos\n",
    "- Tipo: Base de datos SQLite\n",
    "- Caracter√≠sticas:\n",
    "    - Creado autom√°ticamente en la primera ejecuci√≥n\n",
    "    - Almacena todos los planes de fiesta\n",
    "    - Permite consultas y estad√≠sticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flujo de Datos**\n",
    "\n",
    "1. El usuario ingresa los detalles de la fiesta en la interfaz de Streamlit\n",
    "2. La app invoca al `PartyCoordinator` para planificar la fiesta\n",
    "3. Los agentes (Chef, DJ, Decorador) colaboran entre s√≠:\n",
    "    - El Chef propone el men√∫ basado en la tem√°tica\n",
    "    - El DJ recibe las sugerencias del Chef y adapta la m√∫sica\n",
    "    - El Decorador recibe sugerencias de ambos y coordina la decoraci√≥n\n",
    "4. Los resultados se guardan en la base de datos\n",
    "5. La interfaz presenta los resultados de manera visual al usuario\n",
    "\n",
    "Este sistema demuestra un ejemplo did√°ctico de m√∫ltiples agentes colaborando para resolver un problema, con persistencia de datos y una interfaz de usuario moderna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.20.5.241:8501\u001b[0m\n",
      "\u001b[0m\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!streamlit run planificador_fiestas_app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ BONUS: Paso 7 : OPEA Agents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ultimo, nos enfocaremos en una implementacion real de un chatbot usando agentes. Al momento de una implementacion en produccion de AI, se tiene que tener en cuenta como se va a paquetizar la aplicacion para ayudar a la escalabilidad y mejor manejo de las dependencias. \n",
    "Tenemos entonces que pasar de un Jupyter notebook o script a una aplicacion basada en Microservicios. Esto consiste en separar y aislar cada funcionalidad de la applicacion en peque√±as partes. Cuenta con complejidades ya que siendo un projecto orientado a desarollo de plataformas se necesita una infraestructura detras tal como kubernetes, o containers. Pero se comparte a modo informativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ejemplo se puede encontrar aqui [OPEA repo](https://github.com/opea-project/GenAIExamples/tree/main/AgentQnA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will be using OpenAI models, in this case GPT-40-mini as an external inference API. You can easily use a local model\n",
    "\n",
    "<div style=\"background-color: white; display: inline-block;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/opea-project/GenAIComps/main/comps/agent/src/sql_agent.png\" alt=\"SQL Agent\">\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
